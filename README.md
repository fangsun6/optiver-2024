
# Enefit - Predict Energy Behavior of Prosumers Solution

### Competition Overview

**The goal of this competition is to create a model that predicts the energy usage of prosumers (energy consumers who also produce energy), in order to reduce the cost of energy imbalance.**

This competition addresses the issue of energy imbalance, which occurs when the expected and actual energy usage or production are not aligned. Prosumersâ€”who both consume and produce energyâ€”are among the primary contributors to this imbalance. Although they constitute a small fraction of total consumers, their unpredictable behavior presents logistical and financial challenges for energy providers.

### Evaluation Metric

The evaluation is based on the Mean Absolute Error (MAE) between predicted and observed values:

$$
MAE = \frac{1}{n} \sum\limits_{i=1}^{n} {|y_i - x_i|}
$$

- \( n \): total number of data points  
- \( y_i \): prediction for the \( i \)-th data point  
- \( x_i \): actual observation for the \( i \)-th data point

**Submission**  
Submissions must use the provided Python time series API to prevent models from peeking into the future. Use the example notebook as a guide.

### Data Description

The task is to predict electricity consumption and generation of Estonian clients with installed solar panels. Youâ€™ll use weather data, energy prices, and records of PV installation capacity.

This is a forecasting challenge using a time series API. The private leaderboard is based on real data collected after the submission period.

ðŸ’¡ Note: All timestamps are in EET/EEST. Most variables are hourly aggregates. For weather data, timestamps often refer to the end of an hour; all other timestamps refer to the start.

**Files**

- **train.csv**:  
    - `county`, `is_business`, `product_type`, `target`, `is_consumption`, `datetime`, `data_block_id`, `row_id`, `prediction_unit_id`
- **client.csv**:  
    - `product_type`, `county`, `eic_count`, `installed_capacity`, `is_business`, `date`, `data_block_id`
- **gas_prices.csv**, **electricity_prices.csv**:  
    - Include `origin_date`, `forecast_date`, prices, `data_block_id`
- **forecast_weather.csv**:  
    - Forecasts for up to 48 hours, includes temperature, dewpoint, wind, cloud cover, solar radiation, etc.
- **historical_weather.csv**:  
    - Weather data for 2 days before the target datetime, includes temperature, rain, snow, pressure, radiation, wind

- **public_timeseries_testing_util.py**: Optional helper for running offline API tests.
- **example_test_files/**: Sample files showing API behavior, includes `sample_submission.csv`, `revealed_targets.csv`
- **enefit/**: Files for enabling the API; expected to deliver predictions within 15 minutes and under 0.5 GB memory.

### Data Preprocessing

Steps:

1. Load data using `polars`
2. Filter training data to post-2021
3. Use `update_with_new_data` to refresh data in each iteration

### Feature Engineering

**General Features**:
- `dayofyear`, `hour`, `day`, `weekday`, `month`, `year`
- `segment`: combination of `county`, `is_business`, `product_type`, `is_consumption`
- Sinusoidal transforms for cyclical features: `sin(dayofyear)`, `cos(dayofyear)`, `sin(hour)`, `cos(hour)`

**Client Info Features**:
- `installed_capacity`
- Shift `date` forward 2 days to match target datetime, then join on identifiers

**Holiday Features**:
- `is_country_holiday`: Boolean flag for Estonian holidays

**Weather Forecast Features**:
- Merge on location
- Use features like temperature, radiation, precipitation
- Lag forecasts by -1, 0, 1, 2, 7 days
- Add features like `temperature_forecast_local_0h/168h`

**Target Features**:
- Aggregate targets by time and attributes
- Lag targets by 2â€“14 days
- Compute stats like `target_mean`, `target_max`, `target_min`, `target_std`
- Compute lag ratio features

**Other Handling**:
- `_reduce_memory_usage`: Convert `float64` to `float32`
- `_drop_columns`: Drop unused columns

**Final Transformation**:
- Convert to Pandas DataFrame
- Set categorical types for categorical features

### Models

Models use LightGBM.

**5 Consumption Models**:
- `model_consumption`
- `model_consumption_diff_168`
- `model_consumption_diff_48`
- `model_consumption_diff_mean_2`
- `model_consumption_diff_mean`

**4 Production Models**:
- `model_production_diff_48`
- `model_production_diff_mean_2`
- `model_production_diff_mean`
- `model_production_norm`: uses target normalized by installed capacity

Final prediction is a weighted average across models with `np.clip` for value bounding.

### Summary

We built a comprehensive time series forecasting pipeline for the Enefit competition to predict energy consumption and production. We combined data cleaning and feature engineering across multiple sources: client info, weather forecasts, historical weather, prices, and holidays.

We used `polars` for efficient preprocessing, engineered time, client, weather, and lagged target features. Models were trained using LightGBM and aggregated using weighted averages with clipping. This boosted accuracy and helped reduce energy imbalance costs. The project significantly enhanced our understanding of time series modeling and feature engineering.
